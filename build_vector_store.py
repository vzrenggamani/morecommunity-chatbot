#!/usr/bin/env python3
"""
Pre-build Vector Store Script for Rare Disease Helper Chatbot

This script pre-builds the vector store to eliminate cold starts in production.
Run this script whenever you add or modify documents in the data/ folder.

Usage:
    python build_vector_store.py
    python build_vector_store.py --force  # Force rebuild even if up-to-date
"""

# Patch for ChromaDB compatibility (same as app.py)
try:
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
    print("‚úÖ SQLite patch applied for ChromaDB compatibility")
except ImportError:
    print("‚ÑπÔ∏è  pysqlite3 not available, using system sqlite3")

import os
import sys
import glob
import argparse
from datetime import datetime
from langchain_community.document_loaders import UnstructuredMarkdownLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import Chroma

def determine_document_type(file_path):
    """Determine document type based on folder structure"""
    if 'medical_reference' in file_path:
        return 'medical_reference'
    elif 'user_stories' in file_path:
        return 'user_story'
    elif 'community_resources' in file_path:
        return 'community_resource'
    elif 'clinical_guidelines' in file_path:
        return 'clinical_guideline'
    else:
        return 'general'

def should_rebuild_vectorstore(vector_store_path, data_path='./data'):
    """Check if vector store needs rebuilding based on file timestamps"""
    if not os.path.exists(vector_store_path):
        return True, "Vector store tidak ditemukan"

    # Get vector store timestamp
    try:
        vectorstore_timestamp = os.path.getmtime(vector_store_path)
    except:
        return True, "Tidak dapat membaca timestamp vector store"

    # Check all markdown files
    md_files = glob.glob(f'{data_path}/**/*.md', recursive=True)
    if not md_files:
        return False, "Tidak ada file markdown ditemukan"

    # Check if any document is newer than vector store
    for file_path in md_files:
        try:
            file_timestamp = os.path.getmtime(file_path)
            if file_timestamp > vectorstore_timestamp:
                return True, f"Dokumen {os.path.basename(file_path)} telah diperbarui"
        except:
            continue

    return False, "Vector store masih up-to-date"

def load_and_process_documents(data_path='./data'):
    """Load and process all markdown documents"""
    print("üìñ Memuat dokumen dari direktori 'data'...")

    # Check if data directory exists
    if not os.path.exists(data_path):
        print(f"‚ùå Data directory tidak ditemukan: {data_path}")
        print(f"   Current working directory: {os.getcwd()}")
        print(f"   Directory contents: {os.listdir('.')}")
        return None

    all_docs = []
    md_files = glob.glob(f'{data_path}/**/*.md', recursive=True)

    if not md_files:
        print(f"‚ùå Tidak ada file markdown ditemukan di direktori {data_path}/")
        print(f"   Directory contents: {os.listdir(data_path) if os.path.exists(data_path) else 'Directory not found'}")
        return None

    doc_counts = {}

    for file_path in md_files:
        try:
            print(f"   Loading: {file_path}")
            loader = UnstructuredMarkdownLoader(file_path)
            docs = loader.load()

            # Add document type metadata
            doc_type = determine_document_type(file_path)
            for doc in docs:
                doc.metadata['document_type'] = doc_type
                doc.metadata['source_category'] = doc_type
                doc.metadata['original_source'] = file_path
                doc.metadata['build_timestamp'] = datetime.now().isoformat()

            all_docs.extend(docs)
            doc_counts[doc_type] = doc_counts.get(doc_type, 0) + len(docs)
            print(f"‚úÖ Memuat {len(docs)} dokumen dari {doc_type}: {os.path.basename(file_path)}")

        except Exception as e:
            print(f"‚ùå Gagal memuat file {file_path}: {e}")
            import traceback
            print(f"   Error details: {traceback.format_exc()}")
            continue

    if not all_docs:
        print("‚ùå Tidak ada dokumen yang berhasil dimuat!")
        return None

    # Show summary
    summary = ", ".join([f"{count} {dtype}" for dtype, count in doc_counts.items()])
    print(f"‚úÖ Total dokumen dimuat: {len(all_docs)} ({summary})")

    return all_docs

def build_vector_store(force_rebuild=False):
    """Build or rebuild the vector store"""
    vector_store_path = "chroma_db"

    print(f"üìç Working directory: {os.getcwd()}")
    print(f"üìç Vector store path: {os.path.abspath(vector_store_path)}")
    print(f"üìç Data directory exists: {os.path.exists('./data')}")

    # Check if rebuild is needed
    if not force_rebuild:
        needs_rebuild, reason = should_rebuild_vectorstore(vector_store_path)
        if not needs_rebuild:
            print(f"‚úÖ Vector store sudah up-to-date: {reason}")
            return True
        print(f"üîÑ Membangun ulang vector store: {reason}")
    else:
        print("üîÑ Force rebuild vector store...")

    # Load documents
    all_docs = load_and_process_documents()
    if not all_docs:
        print("‚ùå Tidak ada dokumen untuk diproses")
        return False

    try:
        print("üìù Membuat text chunks...")
        # Split documents into chunks
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=100
        )
        texts = text_splitter.split_documents(all_docs)
        print(f"‚úÖ Dibuat {len(texts)} text chunks")

        print("üß† Membuat embeddings dengan Google AI...")
        # Initialize embeddings
        try:
            embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
            # Test the embeddings with a simple text
            test_embedding = embeddings.embed_query("test")
            print(f"‚úÖ Embeddings initialized successfully (dimension: {len(test_embedding)})")
        except Exception as e:
            print(f"‚ùå Failed to initialize embeddings: {e}")
            raise

        # Remove existing vector store if it exists
        if os.path.exists(vector_store_path):
            try:
                import shutil
                # Try to remove it, but handle the case where it's mounted and locked
                shutil.rmtree(vector_store_path)
                print("üóëÔ∏è Vector store lama telah dihapus")
            except OSError as e:
                if e.errno == 16:  # Device or resource busy
                    print("‚ö†Ô∏è Vector store directory locked (Docker volume), clearing contents instead...")
                    # Instead of removing the directory, clear its contents
                    for root, dirs, files in os.walk(vector_store_path):
                        for file in files:
                            try:
                                os.remove(os.path.join(root, file))
                            except:
                                pass
                        for dir_name in dirs:
                            try:
                                shutil.rmtree(os.path.join(root, dir_name))
                            except:
                                pass
                    print("üóëÔ∏è Vector store contents cleared")
                else:
                    raise

        print("üíæ Menyimpan ke ChromaDB...")
        # Create and persist vector store
        vector_store = Chroma.from_documents(
            texts,
            embeddings,
            persist_directory=vector_store_path
        )

        # Verify the vector store was created successfully
        collection = vector_store._collection
        document_count = collection.count()
        print(f"‚úÖ Verifikasi: {document_count} dokumen tersimpan di vector store")

        print(f"‚úÖ Vector store berhasil dibuat di: {vector_store_path}")
        print(f"üìä Statistik:")
        print(f"   - Total chunks: {len(texts)}")
        print(f"   - Documents in vector store: {document_count}")
        print(f"   - Vector store size: {get_folder_size(vector_store_path):.1f} MB")
        print(f"   - Build time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        return True

    except Exception as e:
        print(f"‚ùå Gagal membuat vector store: {e}")
        import traceback
        print(f"Error details: {traceback.format_exc()}")
        return False

def get_folder_size(folder_path):
    """Calculate folder size in MB"""
    total_size = 0
    for dirpath, dirnames, filenames in os.walk(folder_path):
        for filename in filenames:
            filepath = os.path.join(dirpath, filename)
            total_size += os.path.getsize(filepath)
    return total_size / (1024 * 1024)  # Convert to MB

def main():
    parser = argparse.ArgumentParser(description='Pre-build vector store for RAG chatbot')
    parser.add_argument('--force', action='store_true',
                       help='Force rebuild even if vector store is up-to-date')
    parser.add_argument('--check', action='store_true',
                       help='Only check if rebuild is needed without building')

    args = parser.parse_args()

    print("üè• Rare Disease Helper Chatbot - Vector Store Builder")
    print("=" * 60)

    if args.check:
        needs_rebuild, reason = should_rebuild_vectorstore("chroma_db")
        if needs_rebuild:
            print(f"üîÑ Rebuild diperlukan: {reason}")
            sys.exit(1)
        else:
            print(f"‚úÖ Vector store up-to-date: {reason}")
            sys.exit(0)

    # Set up environment (you might need to set GOOGLE_API_KEY)
    if 'GOOGLE_API_KEY' not in os.environ:
        print("‚ö†Ô∏è Warning: GOOGLE_API_KEY environment variable not set")
        print("Make sure to set your Google AI API key before running this script")

        # Try to read from .env file if available
        if os.path.exists('.env'):
            try:
                with open('.env', 'r') as f:
                    for line in f:
                        if line.startswith('GOOGLE_API_KEY='):
                            key = line.split('=', 1)[1].strip().strip('"')
                            os.environ['GOOGLE_API_KEY'] = key
                            print("‚úÖ API key loaded from .env file")
                            break
            except:
                pass

        if 'GOOGLE_API_KEY' not in os.environ:
            print("‚ùå Please set GOOGLE_API_KEY environment variable")
            sys.exit(1)

    # Build vector store
    success = build_vector_store(force_rebuild=args.force)

    if success:
        print("\nüéâ Vector store berhasil dibuat!")
        print("Sekarang aplikasi Streamlit akan load lebih cepat.")
    else:
        print("\n‚ùå Gagal membuat vector store")
        sys.exit(1)

if __name__ == "__main__":
    main()
